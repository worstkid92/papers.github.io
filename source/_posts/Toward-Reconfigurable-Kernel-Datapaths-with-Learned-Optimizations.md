---
title: Toward Reconfigurable Kernel Datapaths with Learned Optimizations
date: 2023-12-08 14:34:10
tags:
---
# Abstract
作者提出了一种使内核能够自我优化的架构。在这种架构中，优化是通过使用机器学习（ML）从经验数据中计算出来的，并通过内核虚拟机以安全和系统化的方式集成到内核中。这个虚拟机实现了可重新配置的匹配表（RMT）抽象，其中表格被安装到内核中，当性能关键事件发生时，匹配查找当前的执行上下文，动作编码由ML计算出的上下文特定优化，这可能会因应用程序而异。他们设想的架构将支持离线和在线学习算法，以及各种内核子系统。RMT验证器将在将RMT程序接纳到内核之前检查程序的良好形式和模型效率。一个被接纳的程序可以被解释为字节码或即时编译以优化内核数据路径。

# 1Inteoduction
操作系统内核正面临来自上下的压力。作为通用资源管理器，操作系统内核需要支持不同的应用，并需要在不同类型的硬件平台上进行多路复用。近来，应用和硬件平台都在快速多样化。
例如，在应用方面，容器或微服务工作负载对延迟敏感，而类似MapReduce的数据处理任务则以IO密集型（例如，用于批量同步、检查点或恢复）的吞吐量为导向。家庭用户应用程序（例如，文档或照片编辑软件）是另一类，具有自己复杂的磁盘IO模式和与云的频繁交互。这种复杂性确保了不存在一种适合所有场景的优化策略。
同样，硬件技术的发展速度超过了软件系统栈，每一代的特性都有所不同，甚至每一代内部，不同供应商的产品也有所不同。对硬盘最好的IO调度算法对SSD和密度优化的覆盖磁盘来说肯定会表现不佳。更进一步复杂化的是，设备正在变得更智能，封装了运行专有算法的嵌入式控制器进行本地管理。在设备中运行这些无法控制的黑箱代码可能会混淆甚至最优化的内核优化。
这两种趋势的汇合要求我们从根本上重新思考操作系统内核应如何为特定场景专门化以提高性能，以及这些专门化如何推广到可能出现的未见过的场景。最近的两种方法可以被视为接近这个目标。内核绕过方法认为资源管理最好留给应用程序。用户态应用程序被直接访问网络卡或磁盘（例如，使用DPDK/SPDK），并根据需要实现自己的优化。另外，eBPF允许应用程序动态地将受限的代码注入到内核中进行定制，以达到类似的效果。
然而，这两种方法都没有回答在什么时候应该实施什么优化的问题。应用程序可能没有足够的知识来充分地实现好的优化，任何改变可能会被新的硬件所无效。当各个应用程序选择自己的策略时，内核也失去了进行跨应用程序优化所需的集中视图。
我们的愿景：可重新配置的内核数据路径。在这篇论文中，我们主张一种根本不同的方法，并提供了一个答案，这个答案从两个最近的工作中得到启发——越来越强大的机器学习（ML）技术，以及使用可重新配置的匹配表（RMT）专门化网络堆栈的努力。我们的关键思想是开发可重新配置的内核数据路径，其中的机制基于内核中的RMT风格的架构，策略是使用ML学习的。操作系统内核动态地以RMT程序的形式发现每个场景的最佳策略，并通过配置内核虚拟机来执行这些策略。通过将这种可编程但轻量级的原语转化为操作系统内核，我们提供了一种允许各种类型适应性的架构。通过利用ML的力量，我们可以消除今天的内核数据路径中大量的最佳努力启发式方法，并使优化能够推广到未见过的应用、工作负载或硬件平台。
在20世纪90年代，应用特定的内核优化和扩展得到了深入的研究。Exokernel主张完全消除操作系统抽象，并将其实现留给应用程序。另一方面，SPIN允许应用程序将安全代码注入到内核中进行动态扩展。他们与内核绕过和eBPF注入的现代等价物有类似的限制。相比之下，我们的想法的一个关键目标是通过基于ML的重新配置自动识别内核优化，因此应用程序不再需要以一次性的方式专门化内核。
研究挑战。实现我们的可重新配置内核数据路径的愿景需要应对一系列挑战：将RMT风格的虚拟机架构到内核中，开发轻量级的内核学习算法，以及将架构应用到关键的内核子系统（例如，调度、内存管理、文件系统、网络）。我们希望在减少操作系统税收方面取得显著的进展：据报道，内核执行占据了数据中心CPU周期的20%，而数据中心代表了全球电力消耗的1%。因此，提高操作系统内核的效率对于广泛的部署场景具有重要的意义。

# 2Motivation
机器学习技术在计算机系统中取得了早期但成功的结果，取代了用于数据检索的精心调整的索引结构，预测硬件设备状态以实现更好的管理，以及有效地管理C++对象内存。张和黄认为，机器学习应该应用到操作系统内核中。我们的想法受到了这项工作的启发，它提出了一种系统化的方法，通过RMT虚拟机将机器学习集成到内核中。
## 2.1 预期的好处
 我们相信，可重配置的内核数据路径有可能释放出四类在今天的操作系统内核中难以实现的好处。
### 1. 精简监控：
操作系统内核使用了大量的运行时监控器，目的是描述当前的工作负载并激活不同的内置启发式算法。然而，这些监控事件引入了缓存污染、运行时开销，而且在某些情况下，它们通过故意引起一些性能下降来工作。后者的一个例子是在NUMA机器上的CPU调度器——为了检测内存亲和性，调度器需要监控线程的页面级访问模式；Linux通过周期性地取消映射进程的页面来做到这一点，这样内核就可以捕获页面错误并监控访问位置。通过引入机器学习，我们可能可以使内核减少必要的监控。例如，使用特征重要性排名[33]的特征选择过程可能允许内核放弃监控那些提供的信息很少的事件。 
### 2. 更好的配置：
操作系统内核中的启发式算法和配置参数的广泛范围可能并不是最优的；调整内核参数以实现更好的配置也是一项具有挑战性的任务。此外，启发式算法只有在引导阶段之后才会被激活（例如，这个特定的线程是I/O绑定的吗？那么就提高它的调度优先级）。在我们的设计中，机器学习算法应该能够探索更广泛的决策策略，从而得到更好的配置参数、明智的策略和更高的性能。如果操作系统内核可以预测应用程序的行为，那么引导阶段可能会被缩短甚至消除，只要应用程序启动，就激活一个合适的配置。配置参数和策略也可以在应用程序运行时进行调整，而不是静态地配置到内核中。
### 3. 泛化：
机器学习的另一个强大特性是它能够对某些任务的未见过的数据点进行泛化[38]。用机器学习模型替换内核中手工制作的、特定的启发式算法可能会导致更稳健的决策。在今天的内核中，展示新行为的应用程序，这些行为没有被现有的启发式算法捕获，通常会有不透明和不可预测的性能。这些性能悬崖只能通过广泛的、通常是针对特定应用的基准测试，由内核开发社区在一段时间内慢慢地捕获和修复。 
### 4. 跨应用优化：
此外，我们的愿景使内核能够学习多个应用程序的行为，它们之间的关系，以及联合优化的机会。这些跨应用的优化将导致更好的系统范围的资源分配。例如，监控可能会检测到任务表现出生产者-消费者行为，并激活优化以实现有效的通信。 当然，机器学习并不是灵丹妙药——一般来说，需要谨慎地将正确的学习技术与正确的问题相匹配[38]。同样的原则也应该适用于操作系统内核：机器学习的有效性将自然地根据手头的任务而变化，在某些情况下，精心调整的启发式算法可能已经走得很远。我们的立场是，机器学习技术在操作系统内核的背景下具有重大的前景，这篇论文是对更彻底的调查的号召。

## 2.2 为什么选择RMT？
为了利用机器学习，我们需要一个适合将其集成到内核的架构。这样的架构必须满足一系列的属性：
• 足够通用：我们需要一个通用的架构，可以表示不同类型的重配置需求，适用于各种内核组件，也适用于学习的不同阶段（例如，数据收集、训练和推理）。
• 受限的：重配置的形式必须受限，以便人们可以轻松地推理和验证配置的正确性，然后再将其安装到内核中。
• 轻量级的：它应该能够以小的运行时开销实现高效的重配置。理想情况下，它应该是硬件友好的，以便可以将其合理地集成到CPU架构中，就像页面表遍历器已经被标准化到硬件中一样。
我们提出的答案是基于可重配置匹配表（RMT），这是网络社区中的一项最近的发展，专门用于专门化网络数据平面。一个RMT程序由一系列可重配置表的管道组成，其中进行专门的数据包处理。表的执行执行匹配，检查一个或多个数据包头字段，并触发基于匹配结果激活不同处理的动作。RMT编程模型受限，但对于广泛的重配置场景来说足够通用，并且已经被证明在高速（Tbps）下是可行的。这些属性使RMT成为内核重配置的有吸引力的候选者，其中存在类比：表是决策点（例如，预取），匹配检查当前的执行环境（例如，过去的访问模式），动作咨询一个机器学习模型（例如，预测要预取的下一组页面）。

# 3 可重配置内核数据路径
在这一部分，我们描述我们的设计，它的研究挑战，以及暂定的解决方案。

## 3.1 内核中的RMT虚拟机
一个RMT程序是由机器学习从过去或当前的运行中产生的，并且它是从用户空间注入到内核的。该程序在虚拟机中以解释模式运行，或者它是即时（JIT）编译为机器代码以提高效率。许多机制类似于eBPF [49]，但RMT程序与eBPF的形式不同，因为它们是为机器学习定制的。
RMT程序。RMT程序的关键构建块是匹配/动作表的管道。每个表代表一个内核挂钩点，可能会触发关于当前执行的数据收集，拦截性能关键的内核事件，或者根据执行上下文咨询机器学习模型。一个RMT程序可以用受限的C或特定领域的语言编写，并编译成机器无关的字节码，通过系统调用安装。程序验证器检查良好的形式和有界的执行，并阻止任意的内核调用或数据修改。RMT字节码可以进一步被即时编译直接为机器代码以提高效率。在运行时，一个RMT程序可以访问一组受限的内核函数，这些函数专门用于学习和推理。它还可以访问存储执行上下文、历史数据和机器学习模型本身的内核内存。