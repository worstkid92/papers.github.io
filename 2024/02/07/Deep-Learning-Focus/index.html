<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Deep Learning Focus | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="quoted, url:https:&#x2F;&#x2F;cameronrwolfe.substack.com&#x2F;p&#x2F;language-model-training-and-inferencehttps:&#x2F;&#x2F;cameronrwolfe.substack.com&#x2F;p&#x2F;graph-based-prompting-and-reasoning#%C2%A7the-transformer-from-top-to-bottomh">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning Focus">
<meta property="og:url" content="https://worstkid92.github.io/papers.github.io/2024/02/07/Deep-Learning-Focus/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="quoted, url:https:&#x2F;&#x2F;cameronrwolfe.substack.com&#x2F;p&#x2F;language-model-training-and-inferencehttps:&#x2F;&#x2F;cameronrwolfe.substack.com&#x2F;p&#x2F;graph-based-prompting-and-reasoning#%C2%A7the-transformer-from-top-to-bottomh">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F89687ad1-ab5d-4c72-840c-343d7fa26ab2_1854x1030.png">
<meta property="og:image" content="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F45501723-a132-40e7-8cb8-5050b2b265fb_1328x378.png">
<meta property="og:image" content="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F57f3c98e-39d1-4eda-9a53-309210d42f49_662x968.png">
<meta property="og:image" content="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F91a045da-57be-437d-962c-529ee5bc93fb_1234x828.png">
<meta property="og:image" content="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2be86a82-3d94-444c-90a2-9428ff629b2f_1994x1404.png">
<meta property="og:image" content="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553be3b4-3c80-435d-88c5-c7079bff9cbb_1940x1090.png">
<meta property="article:published_time" content="2024-02-07T07:37:20.000Z">
<meta property="article:modified_time" content="2024-02-07T09:40:43.621Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F89687ad1-ab5d-4c72-840c-343d7fa26ab2_1854x1030.png">
  
    <link rel="alternate" href="/papers.github.io/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/papers.github.io/favicon.png">
  
  
  
<link rel="stylesheet" href="/papers.github.io/css/style.css">

  
    
<link rel="stylesheet" href="/papers.github.io/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/papers.github.io/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/papers.github.io/">Home</a>
        
          <a class="main-nav-link" href="/papers.github.io/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/papers.github.io/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://worstkid92.github.io/papers.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Deep-Learning-Focus" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/papers.github.io/2024/02/07/Deep-Learning-Focus/" class="article-date">
  <time class="dt-published" datetime="2024-02-07T07:37:20.000Z" itemprop="datePublished">2024-02-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Deep Learning Focus
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="quoted-url"><a href="#quoted-url" class="headerlink" title="quoted, url:"></a>quoted, url:</h1><p><a target="_blank" rel="noopener" href="https://cameronrwolfe.substack.com/p/language-model-training-and-inference">https://cameronrwolfe.substack.com/p/language-model-training-and-inference</a><br><a target="_blank" rel="noopener" href="https://cameronrwolfe.substack.com/p/graph-based-prompting-and-reasoning#%C2%A7the-transformer-from-top-to-bottom">https://cameronrwolfe.substack.com/p/graph-based-prompting-and-reasoning#%C2%A7the-transformer-from-top-to-bottom</a><br><a target="_blank" rel="noopener" href="https://cameronrwolfe.substack.com/p/chain-of-thought-prompting-for-llms">https://cameronrwolfe.substack.com/p/chain-of-thought-prompting-for-llms</a><br><a target="_blank" rel="noopener" href="https://cameronrwolfe.substack.com/p/tree-of-thoughts-prompting">https://cameronrwolfe.substack.com/p/tree-of-thoughts-prompting</a></p>
<h1 id="Language-Model-Scaling-Laws"><a href="#Language-Model-Scaling-Laws" class="headerlink" title="Language Model Scaling Laws"></a>Language Model Scaling Laws</h1><p>url:<a target="_blank" rel="noopener" href="https://cameronrwolfe.substack.com/p/language-model-scaling-laws-and-gpt#%C2%A7language-models-are-few-shot-learners">https://cameronrwolfe.substack.com/p/language-model-scaling-laws-and-gpt#%C2%A7language-models-are-few-shot-learners</a><br><a target="_blank" rel="noopener" href="https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2#%C2%A7prerequisites-for-gpt">https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2#%C2%A7prerequisites-for-gpt</a><br><img src="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F89687ad1-ab5d-4c72-840c-343d7fa26ab2_1854x1030.png" alt="pre-trainning"><br>GPT 模型是利用语言建模目标，通过未标注文本数据的语料库&#x2F;数据集进行预训练的。简单地说，这意味着我们通过以下方式来训练模型：(i) 从数据集中抽取一些文本；(ii) 训练模型预测下一个单词；见上图。这种预训练过程是一种自我监督学习，因为只需查看数据集中的下一个单词，就能确定正确的 “下一个 “单词。</p>
<h2 id="数学中的语言建模。"><a href="#数学中的语言建模。" class="headerlink" title="数学中的语言建模。"></a>数学中的语言建模。</h2><p>要理解语言建模，我们只需掌握上述基本概念。不过，为了使这一点更加严谨，我们可以注意到，我们的语料库只是一组标记。我们可以将标记视为数据集中的单个单词，但这并不完全正确。实际上，标记可能是子词，甚至是字符；<br>有一组tokens<br><img src="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F45501723-a132-40e7-8cb8-5050b2b265fb_1328x378.png" alt="语料库"><br>![modeling loss](<a target="_blank" rel="noopener" href="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws">https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws</a>.<br>com%2Fpublic%2Fimages%2F3430b67c-2d19-4840-9207-09e68a25d03a_1318x444.png)</p>
<h3 id="why-use-log"><a href="#why-use-log" class="headerlink" title="why use log"></a>why use log</h3><p><a target="_blank" rel="noopener" href="https://chrispiech.github.io/probabilityForComputerScientists/en/part1/log_probabilities/">https://chrispiech.github.io/probabilityForComputerScientists/en/part1/log_probabilities/</a><br><a target="_blank" rel="noopener" href="https://www.hackerearth.com/practice/machine-learning/prerequisites-of-machine-learning/bayes-rules-conditional-probability-chain-rule/tutorial/">https://www.hackerearth.com/practice/machine-learning/prerequisites-of-machine-learning/bayes-rules-conditional-probability-chain-rule/tutorial/</a><br>利用语言建模损失（它只是表征我们的模型准确预测序列中下一个标记的能力！），我们可以按照下面的步骤预训练模型参数 θ，从而使损失最小：<br>1.预训练语料库中的样本文本<br>2.用我们的模型预测下一个标记<br>3.使用随机梯度下降（SGD）或其他优化器，提高下一个标记的正确概率<br>通过多次重复这种（自我监督）训练过程，我们的模型最终会成为真正的语言建模高手（即预测序列中的下一个标记）。</p>
<h3 id="什么是语言模型？"><a href="#什么是语言模型？" class="headerlink" title="什么是语言模型？"></a>什么是语言模型？</h3><p>使用这种自监督语言建模目标预先训练的模型通常被称为语言模型（LM）。LM 随着规模的扩大（即层数和参数的增加等）而变得更加有效。因此，我们经常会看到这些模型的大型版本（如 GPT-3），它们被称为大型语言模型 (LLM)。</p>
<h3 id="为什么-LMs-有用？"><a href="#为什么-LMs-有用？" class="headerlink" title="为什么 LMs 有用？"></a>为什么 LMs 有用？</h3><p>LM 可以通过迭代预测最有可能出现的下一个标记来生成连贯的文本，这使得从文本自动完成到聊天机器人等一系列应用成为可能。不过，除了生成能力之外，NLP 领域的前期工作已经表明，LM 预训练对各种任务都有极大的帮助；例如，预训练的词嵌入在下游任务中非常有用，LM预训练可以提高 LSTM 的性能。<br>在这些方法之外，GPT 模型探索了使用转换器进行语言模型预训练的方法。与顺序模型（如 LSTM）相比，变换器（i）具有令人难以置信的表现力（即高表示能力、多参数等），（ii）更适合现代 GPU 的并行计算能力，允许使用更大的模型和更多的数据进行 LM 预训练。这种可扩展性使 LLM 的探索成为可能，而 LLM 已经彻底改变了 NLP 的应用。<br>(tranformers:<a target="_blank" rel="noopener" href="https://cameronrwolfe.substack.com/p/vision-transformers#%C2%A7background">https://cameronrwolfe.substack.com/p/vision-transformers#%C2%A7background</a>)<br><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F57f3c98e-39d1-4eda-9a53-309210d42f49_662x968.png" alt="transformer"></p>
<h2 id="纯解码transformer"><a href="#纯解码transformer" class="headerlink" title="纯解码transformer"></a>纯解码transformer</h2><p>GPT 和 GPT-2 都使用纯解码器变压器架构。上面博客链接里有。<br><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F91a045da-57be-437d-962c-529ee5bc93fb_1234x828.png" alt="decoder-only transformers"><br>decoder-only transformers移除了以下组件：<br>整个编码器模块<br>解码器中的所有编码器-解码器自注意模块<br>移除这些组件后，解码器的每一层都由一个屏蔽自注意层和一个前馈神经网络组成。将几个这样的层堆叠在一起，就形成了一个深度解码器专用变压器架构，例如用于 GPT 或 GPT-2 的架构；</p>
<h3 id="为什么使用解码器？"><a href="#为什么使用解码器？" class="headerlink" title="为什么使用解码器？"></a>为什么使用解码器？</h3><p>选择使用解码器架构（而不是编码器）来处理 LM，因为解码器中的屏蔽的self-attention layers确保了模型在制作标记表示时不能在序列中向前看。与此相反，self-attention（在编码器中使用）允许根据序列中的所有其他标记来调整每个标记的表示。因为在预测下一个标记时，我们不应该向前看句子。使用屏蔽的self-attention layers会产生一种自回归结构（即模型在时间 t 的输出被用作时间 t+1 的输入），它可以持续预测序列中的下一个标记。</p>
<h1 id="chain-of-thought"><a href="#chain-of-thought" class="headerlink" title="chain of thought"></a>chain of thought</h1><p><img src="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2be86a82-3d94-444c-90a2-9428ff629b2f_1994x1404.png" alt="pic.1 chain of thought"></p>
<h1 id="transformer"><a href="#transformer" class="headerlink" title="transformer"></a>transformer</h1><p><img src="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F553be3b4-3c80-435d-88c5-c7079bff9cbb_1940x1090.png" alt="pic.1 总览"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://worstkid92.github.io/papers.github.io/2024/02/07/Deep-Learning-Focus/" data-id="clsbhg7bb0002j4va2bn4dxfq" data-title="Deep Learning Focus" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/papers.github.io/2024/01/30/Code-Generation-Using-Machine-Learning-A-Systematic-Review/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Code Generation Using Machine Learning: A Systematic Review</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/papers.github.io/tags/FPGA/" rel="tag">FPGA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/papers.github.io/tags/libos-security/" rel="tag">libos,security</a></li><li class="tag-list-item"><a class="tag-list-link" href="/papers.github.io/tags/unikraft-security/" rel="tag">unikraft,security</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/papers.github.io/tags/FPGA/" style="font-size: 10px;">FPGA</a> <a href="/papers.github.io/tags/libos-security/" style="font-size: 10px;">libos,security</a> <a href="/papers.github.io/tags/unikraft-security/" style="font-size: 10px;">unikraft,security</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/papers.github.io/archives/2024/02/">February 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/papers.github.io/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/papers.github.io/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/papers.github.io/archives/2023/11/">November 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/papers.github.io/2024/02/07/Deep-Learning-Focus/">Deep Learning Focus</a>
          </li>
        
          <li>
            <a href="/papers.github.io/2024/01/30/Code-Generation-Using-Machine-Learning-A-Systematic-Review/">Code Generation Using Machine Learning: A Systematic Review</a>
          </li>
        
          <li>
            <a href="/papers.github.io/2024/01/08/GPU-Acceleration-in-Unikernels-Using-Cricket-GPU-Virtualization/">GPU Acceleration in Unikernels Using Cricket GPU Virtualization</a>
          </li>
        
          <li>
            <a href="/papers.github.io/2024/01/08/Loupe-Driving-the-Development-of-OS-Compatibility-Layers/">Loupe: Driving the Development of OS Compatibility Layers</a>
          </li>
        
          <li>
            <a href="/papers.github.io/2023/12/21/reading-list/">reading list</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/papers.github.io/" class="mobile-nav-link">Home</a>
  
    <a href="/papers.github.io/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/papers.github.io/js/jquery-3.6.4.min.js"></script>



  
<script src="/papers.github.io/fancybox/jquery.fancybox.min.js"></script>




<script src="/papers.github.io/js/script.js"></script>





  </div>
</body>
</html>